# scripts/pull_channels_and_update.py
# -*- coding: utf-8 -*-
"""
ูุณุญุจ ุฑูุงุจุท ุงููููุงุช (TNT 1, TNT 2, Sky Sports Main Event UK, Sky Sports Premier League UK)
ูู RAW ูุตุฏุฑ (ALL.m3u) ููุญุฏูุซ premierleague.m3u ุจุงุณุชุจุฏุงู **ุณุทุฑ ุงูุฑุงุจุท ููุท** ุงูุฐู ููู #EXTINF
ูููุณ ุงูููุงุฉุ ูุน ุงูุฅุจูุงุก ุนูู ููุงููุง ููุต ุงููEXTINF ููุง ูู ุชูุงููุง.
ูุง ูุถูู ูููุงุช ุฌุฏูุฏุฉ ุฅู ูู ุชูุฌุฏ ูู ุงูููู ุงููุฏู.
"""

import os
import re
import sys
import base64
from pathlib import Path
from typing import List, Tuple, Dict, Optional
import requests

# ===== ุฅุนุฏุงุฏุงุช (ุจุฏูู ุชุบููุฑ ูุนููุงุชู) =====

SOURCE_URL = os.getenv(
    "SOURCE_URL",
    "https://raw.githubusercontent.com/DisabledAbel/daddylivehd-m3u/f582ae100c91adf8c8db905a8f97beb42f369a0b/daddylive-events.m3u8"
)

DEST_RAW_URL = os.getenv(
    "DEST_RAW_URL",
    "https://raw.githubusercontent.com/a7shk1/m3u-broadcast/refs/heads/main/premierleague.m3u"
)

GITHUB_TOKEN   = os.getenv("GITHUB_TOKEN", "").strip()  # repo contents scope
GITHUB_REPO    = os.getenv("GITHUB_REPO", "a7shk1/m3u-broadcast")
GITHUB_BRANCH  = os.getenv("GITHUB_BRANCH", "main")
DEST_REPO_PATH = os.getenv("DEST_REPO_PATH", "premierleague.m3u")
COMMIT_MESSAGE = os.getenv("COMMIT_MESSAGE", "๐ auto-update premierleague.m3u (every 5min)")

OUTPUT_LOCAL_PATH = os.getenv("OUTPUT_LOCAL_PATH", "./out/premierleague.m3u")

TIMEOUT = 25
VERIFY_SSL = True

# ===== ููุท ุงููููุงุช ุงููุทููุจุฉ =====
WANTED_CHANNELS = [
    "TNT 1",
    "TNT 2",
    "Sky Sports Main Event UK",
    "Sky Sports Premier League UK",
]

# ุฃููุงุท ูุฑููุฉ ููุณูุฑุณ (ูุจุญุซ ุนูู ูุงูู ุณุทุฑ ุงููEXTINF ูู ุงููุตุฏุฑ)
ALIASES: Dict[str, List[re.Pattern]] = {
    "TNT 1": [re.compile(r"\btnt\s*(sports)?\s*1\b", re.I)],
    "TNT 2": [re.compile(r"\btnt\s*(sports)?\s*2\b", re.I)],
    "Sky Sports Main Event UK": [
        re.compile(r"\bsky\s*sports\s*main\s*event\b", re.I),
        re.compile(r"\bsky\s*sports\s*main\s*event\s*uk\b", re.I),
    ],
    "Sky Sports Premier League UK": [
        re.compile(r"\bsky\s*sports\s*premier\s*league\b", re.I),
        re.compile(r"\bsky\s*sports\s*premier\s*league\s*uk\b", re.I),
    ],
}

# ุฃุณูุงุก/ูุฑุงุฏูุงุช ุตุฑูุญุฉ ููุฏูุณุชูููุดู (ูุทุงุจูุฉ ุนูู "ุงุณู ุงูููุงุฉ ุจุนุฏ ุงููุงุตูุฉ")
NAME_ALIASES: Dict[str, List[str]] = {
    "TNT 1": ["tnt 1", "tnt sports 1"],
    "TNT 2": ["tnt 2", "tnt sports 2"],
    "Sky Sports Main Event UK": ["sky sports main event", "sky sports main event uk"],
    # ูููุน ูุทุงุจูุฉ "sky premier league" ุจุฏูู "sports"
    "Sky Sports Premier League UK": ["sky sports premier league", "sky sports premier league uk"],
}

UK_MARKERS = (" uk", "(uk", "[uk", " united kingdom")

# ===== ูุธุงุฆู ูุณุงุนุฏุฉ =====

def fetch_text(url: str) -> str:
    r = requests.get(url, timeout=TIMEOUT, verify=VERIFY_SSL)
    r.raise_for_status()
    return r.text

def parse_m3u_pairs(m3u_text: str) -> List[Tuple[str, Optional[str]]]:
    """ูุญููู ููู m3u ุฅูู [(#EXTINF..., url_or_None), ...]"""
    lines = [ln.rstrip("\n") for ln in m3u_text.splitlines()]
    out: List[Tuple[str, Optional[str]]] = []
    i = 0
    while i < len(lines):
        ln = lines[i].strip()
        if ln.startswith("#EXTINF"):
            url = None
            if i + 1 < len(lines):
                nxt = lines[i + 1].strip()
                if nxt and not nxt.startswith("#"):
                    url = nxt
            out.append((lines[i], url))
            i += 2
            continue
        i += 1
    return out

def extract_channel_name_from_extinf(extinf_line: str) -> str:
    """
    ูุฃุฎุฐ ุณุทุฑ EXTINF ุงููุงูู ููุณุชุฎุฑุฌ ุงุณู ุงูููุงุฉ ุจุนุฏ ุฃูู ูุงุตูุฉ ','.
    ูุซุงู: '#EXTINF:-1, Sky Sports Premier League HD' -> 'Sky Sports Premier League HD'
    """
    try:
        return extinf_line.split(",", 1)[1].strip()
    except Exception:
        return extinf_line

def norm_name(name: str) -> str:
    """
    ุชุจุณูุท ุงูุงุณู ููููุงุฑูุฉ: ุญุฑูู ุตุบูุฑุฉุ ุฅุฒุงูุฉ ุชูุฑุงุฑ ุงููุณุงูุงุชุ
    ุฅุฒุงูุฉ ูููุงุช ุงูุฌูุฏุฉ (hd/fhd/uhd/4k)ุ ุฅุฒุงูุฉ ุฑููุฒ ุฒุงุฆุฏุฉ.
    """
    n = name.lower()
    n = re.sub(r"[\[\]\(\)]+", " ", n)                         # ุฃููุงุณ
    n = re.sub(r"\b(uhd|4k|fhd|hd|sd)\b", " ", n)              # ุฌูุฏุฉ
    n = re.sub(r"[^\w\s]+", " ", n)                            # ุฑููุฒ
    n = re.sub(r"\s+", " ", n).strip()                         # ูุณุงูุฉ ูุงุญุฏุฉ
    return n

def name_matches_target(extinf_line: str, target: str) -> bool:
    """
    ูุทุงุจูุฉ ุตุงุฑูุฉ ุนูู ุงูุฏูุณุชูููุดู: ููุงุฑู "ุงุณู ุงูููุงุฉ ุจุนุฏ ุงููุงุตูุฉ" ูุน aliases ุงููุณููุญุฉ.
    ุชููุน ูุทุงุจูุฉ 'Sky Premier League' ุจุฏูู 'Sports'.
    """
    ch_name = extract_channel_name_from_extinf(extinf_line)
    n = norm_name(ch_name)
    allowed = [norm_name(a) for a in NAME_ALIASES.get(target, [])]
    return n in allowed or any(n.startswith(a + " ") for a in allowed)

def source_matches_target_extinf(extinf_line: str, target: str) -> bool:
    """
    ูุทุงุจูุฉ ูุฑููุฉ ููุณูุฑุณ: ูุจุญุซ ุจูregex ุนูู ุณุทุฑ ุงููEXTINF ูุงูู
    ุญุชู ูู ูุงู ุงุณู ุงูููุงุฉ ุฏุงุฎู ุงูุนููุงู/ุงูุฃููุงุณ (ูุซู (SKY SPORTS PREMIER LEAGUE UK)).
    """
    pats = ALIASES.get(target, [])
    return any(p.search(extinf_line) for p in pats)

def pick_wanted(source_pairs: List[Tuple[str, Optional[str]]]) -> Dict[str, str]:
    """
    ูุฑุฌูุน dict: wanted_name -> stream_url
    ููุชูุท **ุฃูุถู ูุฑุดูุญ** ููู ููุงุฉ ูุทููุจุฉ ูู ุงููุตุฏุฑุ ูุน ุชูุถูู 'UK/๐ฌ๐ง' ุฅู ููุฌุฏ.
    """
    candidates: Dict[str, List[Tuple[str, str]]] = {name: [] for name in WANTED_CHANNELS}

    def has_uk_tag(s: str) -> bool:
        s_low = s.lower()
        return any(tag in s_low for tag in UK_MARKERS) or "๐ฌ๐ง" in s

    for extinf, url in source_pairs:
        if not url:
            continue
        for official_name in WANTED_CHANNELS:
            # ูุทุงุจูุฉ ูุฑูุฉ ุนูู ุงูุณูุฑุณ (ูุงูู ุณุทุฑ EXTINF)
            if source_matches_target_extinf(extinf, official_name):
                candidates[official_name].append((extinf, url))

    picked: Dict[str, str] = {}

    for name, lst in candidates.items():
        if not lst:
            continue

        # ูุธุงู ููุงุท ุจุณูุท:
        # +5 ุฅุฐุง ูุญุชูู UK/๐ฌ๐ง
        # +2 ุฅุฐุง ูุญุชูู "UHD/4K/FHD/HD"
        # +1 ุฅุฐุง ูุญุชูู "EN"/"English"
        def score(item: Tuple[str, str]) -> int:
            ext = item[0]
            sc = 0
            if has_uk_tag(ext): sc += 5
            ext_low = ext.lower()
            if any(q in ext_low for q in (" uhd", " 4k", " fhd", " hd")): sc += 2
            if re.search(r"\b(en|english)\b", ext_low): sc += 1
            return sc

        best = sorted(lst, key=score, reverse=True)[0]
        picked[name] = best[1]

    return picked

def upsert_github_file(repo: str, branch: str, path_in_repo: str, content_bytes: bytes, message: str, token: str):
    base = "https://api.github.com"
    url = f"{base}/repos/{repo}/contents/{path_in_repo}"
    headers = {"Authorization": f"Bearer {token}", "Accept": "application/vnd.github+json"}

    sha = None
    get_res = requests.get(url, headers=headers, params={"ref": branch}, timeout=TIMEOUT)
    if get_res.status_code == 200:
        sha = get_res.json().get("sha")

    payload = {
        "message": message,
        "content": base64.b64encode(content_bytes).decode("utf-8"),
        "branch": branch,
    }
    if sha:
        payload["sha"] = sha

    put_res = requests.put(url, headers=headers, json=payload, timeout=TIMEOUT)
    if put_res.status_code not in (200, 201):
        raise RuntimeError(f"GitHub PUT failed: {put_res.status_code} {put_res.text}")
    return put_res.json()

def render_updated_replace_urls_only(dest_text: str, picked_urls: Dict[str, str]) -> str:
    """
    ููุดู ุนูู ููู ุงููุฌูุฉ ุณุทุฑ-ุจุณุทุฑ:
      - ุฅุฐุง ุตุงุฏู #EXTINF ูููุงุฉ ูุทููุจุฉ ููุฏููุง URL ุฌุฏูุฏ ููุง:
        * ูุจูู ุณุทุฑ ุงููEXTINF ููุง ูู (ุจุฏูู ุฃู ุชุนุฏูู ุนูู ุงูุงุณู/ุงููุต)
        * ูุณุชุจุฏู ุงูุณุทุฑ ุงูุชุงูู (ุฅุฐุง ูุงู URL) ุจุงูุฑุงุจุท ุงูุฌุฏูุฏ ุฃู ูุฏุฑุฌู ุฅุฐุง ููููุฏ.
      - ูุง ูุถูู ูููุงุช ุฌุฏูุฏุฉ ุฅู ูู ุชูู ููุฌูุฏุฉ ุฃุณุงุณูุง.
    """
    lines = [ln.rstrip("\n") for ln in dest_text.splitlines()]
    if not lines or not lines[0].strip().upper().startswith("#EXTM3U"):
        lines = ["#EXTM3U"] + lines

    out: List[str] = []
    i = 0
    while i < len(lines):
        ln = lines[i]
        if ln.strip().startswith("#EXTINF"):
            matched_name = None
            for official_name in WANTED_CHANNELS:
                if name_matches_target(ln, official_name):
                    matched_name = official_name
                    break

            if matched_name and matched_name in picked_urls:
                # ุฃุจูู ุงููEXTINF ููุง ูู ุญุฑูููุง
                out.append(ln)
                new_url = picked_urls[matched_name]

                # ุฅุฐุง ุงูุณุทุฑ ุงููู ุจุนุฏู URL: ุงุณุชุจุฏููุ ูุฅูุง ุฃุฏุฑุฌู
                if i + 1 < len(lines) and lines[i + 1].strip() and not lines[i + 1].strip().startswith("#"):
                    out.append(new_url)
                    i += 2
                    continue
                else:
                    out.append(new_url)
                    i += 1
                    continue

        # ุงูุญุงูุฉ ุงูุนุงุฏูุฉ: ุงูุณุฎ ุงูุณุทุฑ ููุง ูู
        out.append(ln)
        i += 1

    return "\n".join(out).rstrip() + "\n"

def main():
    # 1) ุญููู ุงููุตุฏุฑ ูุงููุฌูุฉ
    src_text = fetch_text(SOURCE_URL)
    dest_text = fetch_text(DEST_RAW_URL)

    # 2) ุงูุชูุท ุฃูุถู ุฑูุงุจุท ุงููููุงุช ุงููุทููุจุฉ ูู ุงููุตุฏุฑ
    pairs = parse_m3u_pairs(src_text)
    picked_urls = pick_wanted(pairs)

    print("[i] Picked URLs:")
    for n in WANTED_CHANNELS:
        tag = "โ" if n in picked_urls else "x"
        print(f"  {tag} {n}")

    # 3) ุญุฏูุซ ุงูููู ุงููุฏู ุจุงุณุชุจุฏุงู ุงูุฑูุงุจุท ููุท
    updated = render_updated_replace_urls_only(dest_text, picked_urls)

    # 4) ุงูุชุจ ุฅูู GitHub ุฃู ูุญูููุง
    token = GITHUB_TOKEN
    if token:
        print(f"[i] Updating GitHub: {GITHUB_REPO}@{GITHUB_BRANCH}:{DEST_REPO_PATH}")
        res = upsert_github_file(
            repo=GITHUB_REPO,
            branch=GITHUB_BRANCH,
            path_in_repo=DEST_REPO_PATH,
            content_bytes=updated.encode("utf-8"),
            message=COMMIT_MESSAGE,
            token=token,
        )
        print("[โ] Updated:", res.get("content", {}).get("path"))
    else:
        p = Path(OUTPUT_LOCAL_PATH)
        p.parent.mkdir(parents=True, exist_ok=True)
        p.write_text(updated, encoding="utf-8")
        print("[i] Wrote locally to:", p.resolve())

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("[x] Error:", e)
        sys.exit(1)
